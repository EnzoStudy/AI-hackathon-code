{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 개요\n",
    "\n",
    "변수 비교를 위한 모델\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파일 업로드 및 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AIDU Library Import\n",
    "from aicentro.session import Session\n",
    "from aicentro.framework.keras import Keras as AiduFrm\n",
    "aidu_session = Session(verify=False)\n",
    "aidu_framework = AiduFrm(session=aidu_session)\n",
    "\n",
    "# 데이터 파일 경로\n",
    "data_path = aidu_framework.config.data_dir\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "# 불필요한 경고 출력을 방지합니다.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#필요한 모델 다운로드\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"xgboost\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"seaborn\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"lightgbm\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"catboost\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 러닝 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#러닝을 위한 모델 선택\n",
    "model_select = {\n",
    "    \n",
    "    'randomforest' : 0,\n",
    "    'lightgbm' : 0,\n",
    "    'catboost' : 1,\n",
    "    'xgboost' : 0,\n",
    "    'softvoting' : 0  \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 결과 출력 디렉토리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#acc 결과 저장 디렉토리\n",
    "acc_data_dir = data_path + \"/fit/accuracy/acc_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 기본 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#파일 명\n",
    "#파일 명\n",
    "\n",
    "BEFORE_FILE_NAME = 'all'\n",
    "AFTER_FILE_NAME = 'after'\n",
    "\n",
    "\n",
    "#전처리 후 train 파일명\n",
    "train_before_file_name = data_path + \"/pre_data/train_preprocessing_\"+BEFORE_FILE_NAME+\".csv\"\n",
    "\n",
    "#전처리 후 train 파일명\n",
    "train_after_file_name = data_path + \"/pre_data/train_preprocessing_\"+AFTER_FILE_NAME+\".csv\"\n",
    "\n",
    "#featureimportance 모델 첫번쨰 파일\n",
    "before_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_\"+BEFORE_FILE_NAME+\".csv\"\n",
    "\n",
    "#featureimportance 모델 두번째 파일\n",
    "after_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_\"+AFTER_FILE_NAME+\".csv\"\n",
    "\n",
    "\n",
    "#featureimportance 비교파일\n",
    "compare_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_age.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_after_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습하기위한 train과 validation 나눔\n",
    "# 일반 데이터\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'], test_size =0.05,random_state=21)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'],random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 후 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "\n",
    "#acc를 구해서 시각화해줌\n",
    "def acc_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    acc = (pred==actual).mean()\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#acc를 구해서 시각화해줌(cross_val_score 사용하는 경우)\n",
    "def acc_eval_add(name_, acc):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    df.to_csv(acc_data_dir,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델학습 (랜덤 포레스트, XGboost, Light GBM, CATboost )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgboost_model_fit (x_train_xg, x_valid_xg, y_train_xg, y_valid_xg, model_name='XGB'):\n",
    "    '''\n",
    "    Cat boost 모델 학습을 위한 함수\n",
    "    \n",
    "    param\n",
    "    x_train_cat: x train data\n",
    "    x_valid_cat: x valid data\n",
    "    y_train_cat: y train data\n",
    "    y_valid_cat: y valid data\n",
    "    model_name: 모델 학습 후 그래프 출력을 위한 텍스트\n",
    "    '''\n",
    "     \n",
    "#     # General Parameter\n",
    "#     booster='gbtree' # 트리,회귀(gblinear) 트리가 항상 더 좋은 성능을 내기 때문에 수정할 필요없다고한다.\n",
    "    \n",
    "#     silent=True  # running message출력안한다. 모델이 적합되는 과정을 이해하기위해선 False으로한다.\n",
    "    \n",
    "#     min_child_weight=10   # 값이 높아지면 under-fitting 되는 경우가 있다. CV를 통해 튜닝되어야 한다.\n",
    "    \n",
    "#     max_depth=8     # 트리의 최대 깊이를 정의함. 루트에서 가장 긴 노드의 거리. 8이면 중요변수에서 결론까지 변수가 9개거친다.\n",
    "#                     # Typical Value는 3-10. \n",
    "    \n",
    "#     gamma =0    # 노드가 split 되기 위한 loss function의 값이 감소하는 최소값을 정의한다. gamma 값이 높아질 수록 알고리즘은 보수적으로 변하고, loss function의 정의\n",
    "#                 #에 따라 적정값이 달라지기때문에 반드시 튜닝.\n",
    "    \n",
    "#     nthread =4    # XGBoost를 실행하기 위한 병렬처리(쓰레드) 갯수. 'n_jobs' 를 사용해라.\n",
    "    \n",
    "#     colsample_bytree=0.8   # 트리를 생성할때 훈련 데이터에서 변수를 샘플링해주는 비율. 보통0.6~0.9\n",
    "    \n",
    "#     colsample_bylevel=0.9  # 트리의 레벨별로 훈련 데이터의  변수를 샘플링해주는 비율. 보통0.6~0.9\n",
    "    \n",
    "#     n_estimators =(int)   #부스트트리의 양 트리의 갯수. \n",
    "    \n",
    "#     objective = 'reg:linear','binary:logistic','multi:softmax',\n",
    "#                 'multi:softprob'  # 4가지 존재.\n",
    "#             # 회귀 경우 'reg', binary분류의 경우 'binary',\n",
    "#             # 다중분류경우 'multi'- 분류된 class를 return하는 경우 'softmax'\n",
    "#             # 각 class에 속할 확률을 return하는 경우 'softprob'\n",
    "    \n",
    "#     random_state =  # random number seed.\n",
    "#                     # seed 와 동일.\n",
    "\n",
    "            \n",
    "     #모델 선언\n",
    "    xgb_model = XGBClassifier(n_jobs=-1)\n",
    "    \n",
    "    \n",
    "#     #1008일 파라미터 최적화 결과\n",
    "#     xgb_model = XGBClassifier(n_jobs=-1,\n",
    "#           max_depth = 6,\n",
    "#           learning_rate= 0.23,\n",
    "#           n_estimators= 299,\n",
    "#           gamma=1.0,\n",
    "#           min_child_weight= 3.2,\n",
    "#           max_delta_step=0.09,\n",
    "#           subsample= 0.7,\n",
    "#           colsample_bytree= 0.58  \n",
    "#             )\n",
    "    \n",
    "    start=time.time()\n",
    "\n",
    "    eval_set = [(x_valid_xg, y_valid_xg)]\n",
    "    \n",
    "    #학습\n",
    "    #logloss가 10회 계선되지 않으면 중단하도록 early stopping 설정 n_estimators=100에서는 얼리스탑하지 않음\n",
    "    xgb_model.fit(x_train_xg, y_train_xg, early_stopping_rounds=10, eval_metric=\"logloss\", eval_set=eval_set, verbose=2)\n",
    "\n",
    "    (time.time()-start)/60\n",
    "    \n",
    "    pred= xgb_model.predict(x_valid_xg)\n",
    "    \n",
    "    acc_eval(model_name, pred,y_valid) #기본\n",
    "    \n",
    "    #모델 및 예측값 return\n",
    "    return xgb_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost 모델 선택시\n",
    "\n",
    "if model_select['xgboost'] == 1:\n",
    "    #모델 학습\n",
    "    xgboost_model, xgboost_pred = xgboost_model_fit (x_train, x_valid, y_train, y_valid, 'xgboost' )\n",
    "    #모델 save\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 CATBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def catboost_model_fit (x_train_cat, x_valid_cat, y_train_cat, y_valid_cat, model_name='CAT'):\n",
    "    '''\n",
    "    Cat boost 모델 학습을 위한 함수\n",
    "    \n",
    "    param\n",
    "    x_train_cat: x train data\n",
    "    x_valid_cat: x valid data\n",
    "    y_train_cat: y train data\n",
    "    y_valid_cat: y valid data\n",
    "    model_name: 모델 학습 후 그래프 출력을 위한 텍스트\n",
    "    '''\n",
    "    #모델 선언\n",
    "    cat_model= CatBoostClassifier()\n",
    "    start=time.time()\n",
    "    \n",
    "    #학습\n",
    "    cat_model.fit(x_train_cat, y_train_cat, verbose=0 )\n",
    "    \n",
    "    #예측 및 결과 확인\n",
    "    pred = cat_model.predict(x_valid_cat)\n",
    "    acc_eval(model_name ,pred, y_valid_cat)\n",
    "    \n",
    "    #모델 및 예측값 return\n",
    "    return cat_model, pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_col = []\n",
    "after_col = []\n",
    "\n",
    "if model_select['catboost'] == 1:\n",
    "\n",
    "#     train_df = pd.read_csv(train_after_file_name)\n",
    "#     x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'],random_state=21,shuffle=False)\n",
    "#     catboost_after_model, catboost_pred = catboost_model_fit (x_train, x_valid, y_train, y_valid, 'catboost_after' )  \n",
    "    \n",
    "    \n",
    "    #모델 학습 진행\n",
    "    for i in range(2):\n",
    "        if i==0:\n",
    "            # before 데이터 나누기\n",
    "            train_df = pd.read_csv(train_before_file_name)\n",
    "            x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'],random_state=21,shuffle=False)\n",
    "            \n",
    "            #학습시작\n",
    "            catboost_before_model, catboost_pred = catboost_model_fit (x_train, x_valid, y_train, y_valid, 'catboost_before' )\n",
    "            before_col = x_train.columns\n",
    "        else:\n",
    "            # after 데이터 나누기\n",
    "            train_df = pd.read_csv(train_after_file_name)\n",
    "            x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'], random_state=21,shuffle=False)\n",
    "            \n",
    "            #학습 시작\n",
    "            catboost_after_model, catboost_pred = catboost_model_fit (x_train, x_valid, y_train, y_valid, 'catboost_after' )\n",
    "            after_col = x_train.columns\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 중요도 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = data_path + \"/episdode1_train_description.csv\"\n",
    "description_ob = data_path + \"/episdode1_train_ob_description.csv\"\n",
    "\n",
    "description_df=pd.read_csv(description)\n",
    "description_ob_df=pd.read_csv(description_ob)\n",
    "\n",
    "#일반 설명과 ob 설명 합치기\n",
    "description_df = pd.concat([description_df,description_ob_df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(2):    \n",
    "    \n",
    "    #변수 중요도 data  Frame 합치기\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    \n",
    "    if i ==0:\n",
    "        feature_importance_dir =before_importance_dir\n",
    "        feature_importance_df['col'] = before_col\n",
    "        feature_importance_df['val'] = catboost_before_model.feature_importances_\n",
    "        \n",
    "    else:\n",
    "\n",
    "        feature_importance_dir =after_importance_dir\n",
    "\n",
    "        feature_importance_df['col'] = after_col\n",
    "        feature_importance_df['val'] = catboost_after_model.feature_importances_\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    for row in range(feature_importance_df.shape[0]):\n",
    "        str_eng= feature_importance_df.loc[row,'col']\n",
    "        for i in description_df['컬럼 영문명']:\n",
    "            if i in str_eng:\n",
    "                feature_importance_df.loc[row,'han'] = description_df.loc[description_df['컬럼 영문명']==i, '컬럼 한글명'].values[0]\n",
    "                \n",
    "    #중요 순서로 sort\n",
    "    feature_importance_df.sort_values(by='val',axis=0,ascending=False,inplace=True)\n",
    "\n",
    "    #그래프 출력\n",
    "    #plt.figure(figsize=(25, 5))\n",
    "    #plt.bar(feature_importance_df['col'],feature_importance_df['val'])\n",
    "    #plt.xticks(rotation=90)\n",
    "    #plt.show()\n",
    "\n",
    "    #파일 출력\n",
    "    feature_importance_df.to_csv( feature_importance_dir,index=False )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#데이터 csv 불러오기 \n",
    "before_importance_df = pd.read_csv(before_importance_dir)\n",
    "after_importance_df = pd.read_csv(after_importance_dir)\n",
    "\n",
    "\n",
    "#랭크 계산 \n",
    "before_importance_df['rank']= range(1,before_importance_df.shape[0]+1)\n",
    "before_importance_df.columns=['col','han','before_score','before_rank']\n",
    "after_importance_df['rank'] = range(1,after_importance_df.shape[0]+1)\n",
    "after_importance_df.columns=['col','han','after_score','after_rank']\n",
    "\n",
    "#이전, 이후 데이터 합치기\n",
    "compare_importance_df = pd.DataFrame()\n",
    "compare_importance_df = before_importance_df\n",
    "compare_importance_df=pd.merge(compare_importance_df,after_importance_df ,how='outer', on='col')\n",
    "compare_importance_df.drop('han_y',axis=1,inplace=True)\n",
    "\n",
    "\n",
    "#차이 계산\n",
    "compare_importance_df['differ_rank']= compare_importance_df['before_rank']-compare_importance_df['after_rank']\n",
    "compare_importance_df['abs_differ_rank'] = compare_importance_df['differ_rank'].abs()\n",
    "\n",
    "#정렬\n",
    "compare_importance_df.sort_values(by='abs_differ_rank',ascending=False ,inplace=True)\n",
    "compare_importance_df.drop(['abs_differ_rank'],axis=1,inplace=True)\n",
    "\n",
    "#데이터 출력\n",
    "compare_importance_df.to_csv(compare_importance_dir, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.bar(x=compare_importance_df['col'].head(10),height=compare_importance_df['differ_rank'].head(10))\n",
    "plt.xticks(compare_importance_df['col'].head(10),fontsize=20,rotation=45)\n",
    "# compare_importance_df.head(10).plot.bar(x='col', y='differ_rank', rotation=45)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 결과 불러오기 \n",
    "eda_before_file_name = data_path + \"/fit/eda_result_check_\"+BEFORE_FILE_NAME+\".csv\"\n",
    "eda_after_file_name = data_path + \"/fit/eda_result_check_\"+AFTER_FILE_NAME+\".csv\"\n",
    "compare_importance_df['이전 전처리결과']='-'\n",
    "\n",
    "#데이터 csv 불러오기 \n",
    "before_eda_df = pd.read_csv(eda_before_file_name)\n",
    "after_eda_df = pd.read_csv(eda_after_file_name)\n",
    "\n",
    "\n",
    "\n",
    "for row in compare_importance_df['col']:\n",
    "        \n",
    "    try:\n",
    "        #이후 데이터 받아오기\n",
    "        col_str = compare_importance_df.loc[compare_importance_df['col']==row,'col'].values[0]\n",
    "\n",
    "        for eda_data in before_eda_df['기준컬럼']:\n",
    "            if eda_data in col_str:\n",
    "                compare_importance_df.loc[compare_importance_df['col']==row,'이전 전처리결과'] =before_eda_df.loc[before_eda_df['기준컬럼']==eda_data,'전처리결과' ].values[0]\n",
    "                \n",
    "       # 이후 전처리 결과 받아오기      \n",
    "        col_str = compare_importance_df.loc[compare_importance_df['col']==row,'col'].values[0]\n",
    "\n",
    "        for eda_data in after_eda_df['기준컬럼']:\n",
    "            if eda_data in col_str:\n",
    "                \n",
    "                compare_importance_df.loc[compare_importance_df['col']==row,'이후 전처리결과'] =after_eda_df.loc[after_eda_df['기준컬럼']==eda_data,'전처리결과' ].values[0]\n",
    "                \n",
    "\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "compare_importance_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
