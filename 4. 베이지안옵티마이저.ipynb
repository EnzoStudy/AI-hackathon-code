{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "베이지안옵티마이저 (xgboost) 코드\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파일 업로드 및 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AIDU Library Import\n",
    "from aicentro.session import Session\n",
    "from aicentro.framework.keras import Keras as AiduFrm\n",
    "aidu_session = Session(verify=False)\n",
    "aidu_framework = AiduFrm(session=aidu_session)\n",
    "\n",
    "# 데이터 파일 경로\n",
    "data_path = aidu_framework.config.data_dir\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "# 불필요한 경고 출력을 방지합니다.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#필요한 모델 다운로드\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"xgboost\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"seaborn\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"lightgbm\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"catboost\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"bayesian-optimization\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기 및 기본 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#Train file 데이터 디렉토리\n",
    "train_file_dir = data_path + \"/episode1_train.csv\"\n",
    "train_ob_file_dir = data_path + \"/episode1_train_ob.csv\"\n",
    "\n",
    "#Test file 데이터 디렉토리\n",
    "test_file_dir = data_path + \"/episode1_test.csv\"\n",
    "test_ob_file_dir = data_path + \"/episode1_test_ob.csv\"\n",
    "\n",
    "\n",
    "#전처리 후 test 파일명\n",
    "test_file_name =data_path + \"/pre_data/test_preprocessing.csv\"\n",
    "\n",
    "#전처리 후 train 파일명\n",
    "train_file_name = data_path + \"/pre_data/train_preprocessing.csv\"\n",
    "\n",
    "# 최적화 파라미터 결과 파일명\n",
    "xgboost_param_file_name =  data_path + \"/fit/optimizer/xgboost.csv\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(train_file_name)\n",
    "test_df = pd.read_csv(test_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습하기위한 train과 validation 나눔\n",
    "# 일반 데이터\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'],random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 후 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "\n",
    "#acc를 구해서 시각화해줌\n",
    "def acc_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    acc = (pred==actual).mean()\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#acc를 구해서 시각화해줌(cross_val_score 사용하는 경우)\n",
    "def acc_eval_add(name_, acc):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    df.to_csv(acc_data_dir,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이지안 옵티마이즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XGBoost 베이지안옵티마이즈\n",
    "https://wooono.tistory.com/102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#사용하기 위한 import \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이지안 옵티마이저 시작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, r2_score\n",
    "\n",
    "def mean_absolute_percentage_error(y_test, y_pred):\n",
    "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "\n",
    "\n",
    "def XGB_cv(max_depth,learning_rate, n_estimators, gamma, min_child_weight,max_delta_step,subsample,colsample_bytree,silent=True, nthread=-1):\n",
    "    model = xgb.XGBClassifier(max_depth=int(max_depth),\n",
    "                              learning_rate=learning_rate,\n",
    "                              n_estimators=int(n_estimators),\n",
    "                              nthread=nthread,\n",
    "                              gamma=gamma,\n",
    "                              min_child_weight=min_child_weight,\n",
    "                              max_delta_step=max_delta_step,\n",
    "                              subsample=subsample,\n",
    "                              colsample_bytree=colsample_bytree,\n",
    "                              use_label_encoder=False, eval_metric='logloss')\n",
    "    \n",
    "    \n",
    "    eval_set = [(x_valid, y_valid)]\n",
    "\n",
    "#     모델 훈련\n",
    "    model.fit(x_train, y_train,  early_stopping_rounds=5, eval_metric=\"logloss\", eval_set=eval_set, verbose=0)\n",
    "\n",
    "#     예측값 출력\n",
    "    y_pred= model.predict(x_valid)\n",
    "    \n",
    "# metric 계산\n",
    "    acc = accuracy_score(y_valid,y_pred)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 범위 사이에서 적절한 값을 찾는다.\n",
    "pbounds = {'max_depth': (5, 10),\n",
    "          'learning_rate': (0.01, 0.3),\n",
    "          'n_estimators': (50, 300),\n",
    "          'gamma': (1., 0.01),\n",
    "          'min_child_weight': (2, 10),\n",
    "          'max_delta_step': (0, 0.1),\n",
    "          'subsample': (0.7, 0.9),\n",
    "          'colsample_bytree' :(0.5, 0.99)          \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization 객체 생성\n",
    "# f : 탐색 대상 함수, pbounds : hyperparameter 집합\n",
    "# verbose = 2 항상 출력, verbose = 1 최댓값일 때 출력, verbose = 0 출력 안함\n",
    "# random_state : Bayesian Optimization 상의 랜덤성이 존재하는 부분을 통제\n",
    "xgboostBO = BayesianOptimization(f = XGB_cv,pbounds = pbounds, verbose = 2, random_state = 1 )\n",
    "\n",
    "\n",
    "#출력하기\n",
    "out_df = pd.DataFrame(xgboostBO.max)\n",
    "\n",
    "opti_result_file_name = data_path +'/fit/optimizer/optimizer.csv'\n",
    "out_df['rows']= out_df.index\n",
    "out_df.to_csv(opti_result_file_name, header=True, index=True, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메소드를 이용해 최대화 과정 수행\n",
    "# init_points :  초기 Random Search 갯수\n",
    "# n_iter : 반복 횟수 (몇개의 입력값-함숫값 점들을 확인할지! 많을 수록 정확한 값을 얻을 수 있다.)\n",
    "# acq : Acquisition Function들 중 Expected Improvement(EI) 를 사용\n",
    "# xi : exploration 강도 (기본값은 0.0)\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "xgboostBO.maximize(init_points=4, n_iter = 20, acq='ei', xi=0.01)\n",
    "print('BO Time(min): {:.2f}'.format((time.time()-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘iter’는 반복 회차, ‘target’은 목적 함수의 값, 나머지는 입력값을 나타냅니다. \n",
    "# 현재 회차 이전까지 조사된 함숫값들과 비교하여, 현재 회차에 최댓값이 얻어진 경우, \n",
    "# bayesian-optimization 라이브러리는 이를 자동으로 다른 색 글자로 표시하는 것을 확인할 수 있습니다\n",
    "\n",
    "# 찾은 파라미터 값 확인\n",
    "print(xgboostBO.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파라미터 결과 파일로 출력\n",
    "\n",
    "print(dict((xgboostBO.max['params'])))\n",
    "out_param =pd.DataFrame()\n",
    "\n",
    "out_param['param']=list(dict((xgboostBO.max['params'])).keys())\n",
    "out_param['value']=list(dict((xgboostBO.max['params'])).values())\n",
    "\n",
    "out_param.to_csv(xgboost_param_file_name, header=True, index=True, encoding='utf-8'  )\n",
    "print('최대 파라미터가 출력 되었습니다.',xgboost_param_file_name)\n",
    "\n",
    "out_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이지안 결과로 나온 파라미터로 결과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최대 결과로 예측값 \n",
    "fit_xgb = xgb.XGBClassifier(max_depth= int( xgboostBO.max['params']['max_depth'] ),\n",
    "                             learning_rate=xgboostBO.max['params']['learning_rate'],\n",
    "                             n_estimators=int(xgboostBO.max['params']['n_estimators']),\n",
    "                             gamma= xgboostBO.max['params']['gamma'],\n",
    "                             min_child_weight=xgboostBO.max['params']['min_child_weight'],\n",
    "                             max_delta_step=xgboostBO.max['params']['max_delta_step'],\n",
    "                             subsample=xgboostBO.max['params']['subsample'],\n",
    "                             colsample_bytree=xgboostBO.max['params']['colsample_bytree'],\n",
    "                             n_jobs=-1)\n",
    "\n",
    "fit_xgb.fit(x_train,y_train)\n",
    "pred_XGB = fit_xgb.predict(x_valid)\n",
    "\n",
    "#그래프 그리기\n",
    "acc_eval(\"XGBOOST 최적화 후\" ,pred_XGB, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
