{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 개요\n",
    "\n",
    "모델 컬럼 전체중에\n",
    "정확도가 가장 높은 컬럼 조합을 찾아주는 코드\n",
    "\n",
    "RFE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파일 업로드 및 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# AIDU Library Import\n",
    "from aicentro.session import Session\n",
    "from aicentro.framework.keras import Keras as AiduFrm\n",
    "aidu_session = Session(verify=False)\n",
    "aidu_framework = AiduFrm(session=aidu_session)\n",
    "\n",
    "# 데이터 파일 경로\n",
    "data_path = aidu_framework.config.data_dir\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "# 불필요한 경고 출력을 방지합니다.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "#필요한 모델 다운로드\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"xgboost\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"seaborn\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"lightgbm\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"catboost\"])\n",
    "subprocess.call([sys.executable,\"-m\",\"pip\",\"install\",\"probatus\"])\n",
    "\n",
    "\n",
    "#파일 명\n",
    "#파일 명\n",
    "\n",
    "BEFORE_FILE_NAME = 'rfe_feature'\n",
    "AFTER_FILE_NAME = 'rfe_feature'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기 및 기본 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "#전처리 후 train 파일명\n",
    "train_before_file_name = data_path + \"/pre_data/train_preprocessing_\"+BEFORE_FILE_NAME+\".csv\"\n",
    "\n",
    "#전처리 후 train 파일명\n",
    "train_after_file_name = data_path + \"/pre_data/train_preprocessing_\"+AFTER_FILE_NAME+\".csv\"\n",
    "\n",
    "#featureimportance 모델 첫번쨰 파일\n",
    "before_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_\"+BEFORE_FILE_NAME+\".csv\"\n",
    "\n",
    "#featureimportance 모델 두번째 파일\n",
    "after_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_\"+AFTER_FILE_NAME+\".csv\"\n",
    "\n",
    "\n",
    "#featureimportance 비교파일\n",
    "compare_importance_dir = data_path + \"/fit/feature_importance/model_Feature_Importance_age.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_after_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습하기위한 train과 validation 나눔\n",
    "# 일반 데이터\n",
    "# x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'], test_size =0.05,random_state=21)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'],random_state=21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 후 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "my_predictions = {}\n",
    "\n",
    "colors = ['r', 'c', 'm', 'y', 'k', 'khaki', 'teal', 'orchid', 'sandybrown',\n",
    "          'greenyellow', 'dodgerblue', 'deepskyblue', 'rosybrown', 'firebrick',\n",
    "          'deeppink', 'crimson', 'salmon', 'darkred', 'olivedrab', 'olive', \n",
    "          'forestgreen', 'royalblue', 'indigo', 'navy', 'mediumpurple', 'chocolate',\n",
    "          'gold', 'darkorange', 'seagreen', 'turquoise', 'steelblue', 'slategray', \n",
    "          'peru', 'midnightblue', 'slateblue', 'dimgray', 'cadetblue', 'tomato'\n",
    "         ]\n",
    "\n",
    "\n",
    "#acc를 구해서 시각화해줌\n",
    "def acc_eval(name_, pred, actual):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    acc = (pred==actual).mean()\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#acc를 구해서 시각화해줌(cross_val_score 사용하는 경우)\n",
    "def acc_eval_add(name_, acc):\n",
    "    global predictions\n",
    "    global colors\n",
    "\n",
    "    my_predictions[name_] = acc\n",
    "\n",
    "\n",
    "    y_value = sorted(my_predictions.items(), key=lambda x: x[1], reverse=False)  # 정확도 내림차순으로 sort\n",
    "    \n",
    "    df = pd.DataFrame(y_value, columns=['model', 'acc'])\n",
    "    print(df)\n",
    "    min_ = df['acc'].min() -1\n",
    "    max_ = 1.2\n",
    "    \n",
    "    length = len(df)\n",
    "    \n",
    "    plt.figure(figsize=(10, length))\n",
    "    ax = plt.subplot()\n",
    "    ax.set_yticks(np.arange(len(df)))\n",
    "    ax.set_yticklabels(df['model'], fontsize=15)\n",
    "    bars = ax.barh(np.arange(len(df)), df['acc'])\n",
    "    \n",
    "    for i, v in enumerate(df['acc']):\n",
    "        idx = np.random.choice(len(colors))\n",
    "        bars[i].set_color(colors[idx])\n",
    "        ax.text(v+0.1, i, str(round(v, 3)), color='k', fontsize=15, fontweight='bold')\n",
    "        \n",
    "    plt.title('Accuracy', fontsize=18)\n",
    "    plt.xlim(min_,max_)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    df.to_csv(acc_data_dir,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from probatus.feature_elimination import ShapRFECV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop(['label_payment_yn'],axis=1), train_df['label_payment_yn'], random_state=21)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost 모델로 최적의 컬럼 조합 찾아줌\n",
    "clf = CatBoostClassifier( n_estimators = 300)\n",
    "\n",
    "# Run RFECV and ShapRFECV with the same parameters\n",
    "rfe = RFECV(clf, step=1, scoring='roc_auc', n_jobs=-1, verbose=0).fit(X_train, y_train)\n",
    "\n",
    "#step 수 조정으로 서치하는 횟수 감소 가능\n",
    "shap_elimination = ShapRFECV(clf=clf, step=5, scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit\n",
    "shap_report = shap_elimination.fit_compute(X_train, y_train)\n",
    "\n",
    "#shap_report를 통해 결과 데이터프레임 확인\n",
    "shap_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#결과 출력\n",
    "shap_report_df = pd.DataFrame(shap_report)\n",
    "shap_report_df.to_csv(data_path + \"/fit/accuracy/shap_report_jupyter_1012.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
